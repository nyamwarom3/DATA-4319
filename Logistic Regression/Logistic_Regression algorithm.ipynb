{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOGISTIC REGRESSION ALGORITHM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic regression** *is a statistical method for predicting binary classes. The outcome or target variable is dichotomous in nature meaning, there are only two possible classes. For example, it can be used for cancer detection problems. It computes the probability of an event occurrence.*\n",
    "\n",
    "*Logistic regression is a special case of linear regression where the target variable is categorical in nature. It uses a log of odds as the dependent variable. It also predicts the probability of occurrence of a binary event utilizing a logit function.*\n",
    "\n",
    "#### Properties of Logistic Regression:\n",
    "\n",
    "**1.The dependent variable in logistic regression follows Bernoulli Distribution.**\n",
    "\n",
    "**2.Estimation is done through maximum likelihood.**\n",
    "\n",
    "**3.No R Square, Model fitness is calculated through Concordance, KS-Statistics.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading packages\n",
    "using CSV\n",
    "using DataFrames "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = CSV.read(\"candidates_data.csv\", DataFrame)\n",
    "x_data = [[x[1], x[2], x[3]] for x in zip(data.gmat, data.gpa, data.work_experience)]\n",
    "y_data = [x for x in data.admitted];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Lathe.preprocess: TrainTestSplit\n",
    "train, test = TrainTestSplit(data, 0.6);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAIN DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25-element Array{Tuple{Array{Float64,1},Int64},1}:\n",
       " ([780.0, 4.0, 3.0], 1)\n",
       " ([690.0, 3.3, 3.0], 0)\n",
       " ([710.0, 3.7, 5.0], 1)\n",
       " ([680.0, 3.9, 4.0], 0)\n",
       " ([690.0, 2.3, 1.0], 0)\n",
       " ([720.0, 3.3, 4.0], 1)\n",
       " ([740.0, 3.3, 5.0], 1)\n",
       " ([690.0, 1.7, 1.0], 0)\n",
       " ([610.0, 2.7, 3.0], 0)\n",
       " ([690.0, 3.7, 5.0], 1)\n",
       " ([680.0, 3.3, 4.0], 0)\n",
       " ([610.0, 3.0, 1.0], 0)\n",
       " ([650.0, 3.7, 6.0], 1)\n",
       " ([540.0, 2.7, 2.0], 0)\n",
       " ([670.0, 3.3, 6.0], 1)\n",
       " ([660.0, 3.7, 4.0], 1)\n",
       " ([580.0, 2.3, 2.0], 0)\n",
       " ([650.0, 3.7, 6.0], 1)\n",
       " ([640.0, 3.0, 1.0], 0)\n",
       " ([620.0, 2.7, 2.0], 0)\n",
       " ([660.0, 3.3, 6.0], 1)\n",
       " ([670.0, 2.7, 2.0], 0)\n",
       " ([580.0, 3.3, 1.0], 0)\n",
       " ([590.0, 1.7, 4.0], 0)\n",
       " ([690.0, 3.7, 5.0], 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training data\n",
    "train_x = [[x[1], x[2], x[3]] for x in zip(train.gmat, train.gpa, train.work_experience)]\n",
    "train_y = [x for x in train.admitted]\n",
    "train_data = [x for x in zip(train_x, train_y)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running algorithm on train data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "average_cost (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "σ(x) = 1/(1+ exp(-x))\n",
    "\n",
    "function cross_entropy_loss(x, y, w, b)\n",
    "    return -y*log(σ(w'x + b)) - (1-y)*log(1- σ(w'x + b))\n",
    "end\n",
    "\n",
    "function average_cost(features, labels, w, b)\n",
    "    N = length(features)\n",
    "    return (1/N)*sum([cross_entropy_loss(features[i], labels[i], w, b) for i = 1:N])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "batch_gradient_descent (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function batch_gradient_descent(features, labels, w, b, α)\n",
    "    del_w = [0.0 for i = 1:length(w)]\n",
    "    del_b = 0.0\n",
    "    \n",
    "    N = length(features)\n",
    "    \n",
    "    for i = 1:N\n",
    "        del_w += (σ(w'features[i]+b) - labels[i])*features[i]\n",
    "        del_b += (σ(w'features[i]+b) - labels[i])\n",
    "    end\n",
    "    \n",
    "    w = w - α*del_w\n",
    "    b = b - α*del_b\n",
    "    \n",
    "    return w, b\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The initial cost is: 0.6931471805599452\n",
      "The new cost is: 0.6917978742964508\n",
      "The new cost is: 0.6910855407631421\n",
      "The new cost is: 0.6907090512344928\n"
     ]
    }
   ],
   "source": [
    "w = [0.0, 0.0, 0.0]\n",
    "b = 0.0\n",
    "println(\"The initial cost is: \", average_cost(train_x, train_y, w, b))\n",
    "\n",
    "w, b = batch_gradient_descent(train_x, train_y, w, b, 0.0000001)\n",
    "println(\"The new cost is: \", average_cost(train_x, train_y, w, b))\n",
    "\n",
    "w, b = batch_gradient_descent(train_x, train_y, w, b, 0.0000001)\n",
    "println(\"The new cost is: \", average_cost(train_x, train_y, w, b))\n",
    "\n",
    "w, b = batch_gradient_descent(train_x, train_y, w, b, 0.0000001)\n",
    "println(\"The new cost is: \", average_cost(train_x, train_y, w, b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "batch_gradient_descent (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function batch_gradient_descent(features, labels, w, b, α)\n",
    "    del_w = [0.0 for i = 1:length(w)]\n",
    "    del_b = 0.0\n",
    "    \n",
    "    N = length(features)\n",
    "    \n",
    "    for i = 1:N\n",
    "        del_w += (σ(w'features[i]+b) - labels[i])*features[i]\n",
    "        del_b += (σ(w'features[i]+b) - labels[i])\n",
    "    end\n",
    "    \n",
    "    w = w - α*del_w\n",
    "    b = b - α*del_b\n",
    "    \n",
    "    return w, b\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train_batch_gradient_descent (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function train_batch_gradient_descent(features, labels, w, b, α, epochs)\n",
    "    for i = 1:epochs\n",
    "        \n",
    "        w, b = batch_gradient_descent(features, labels, w, b, α)\n",
    "        \n",
    "        if i == 1\n",
    "            println(\"Epoch \", i, \" with cost: \", average_cost(train_x, train_y, w, b))\n",
    "        end\n",
    "        \n",
    "        if i == 10\n",
    "            println(\"Epoch \", i, \" with cost: \", average_cost(train_x, train_y, w, b))\n",
    "        end\n",
    "        \n",
    "        if i == 100\n",
    "            println(\"Epoch \", i, \" with cost: \", average_cost(train_x, train_y, w, b))\n",
    "        end\n",
    "        \n",
    "        if i == 1000\n",
    "            println(\"Epoch \", i, \" with cost: \", average_cost(train_x, train_y, w, b))\n",
    "        end\n",
    "        \n",
    "        if i == 10000\n",
    "            println(\"Epoch \", i, \" with cost: \", average_cost(train_x, train_y, w, b))\n",
    "        end\n",
    "        \n",
    "        if i == 100000\n",
    "            println(\"Epoch \", i, \" with cost: \", average_cost(train_x, train_y, w, b))\n",
    "        end\n",
    "        \n",
    "        if i == 1000000\n",
    "            println(\"Epoch \", i, \" with cost: \", average_cost(train_x, train_y, w, b))\n",
    "        end\n",
    "        \n",
    "        if i == 10000000\n",
    "            println(\"Epoch \", i, \" with cost: \", average_cost(train_x, train_y, w, b))\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return w, b\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 with cost: 36.30210868507543\n",
      "Epoch 10 with cost: 15.397233275476252\n",
      "Epoch 100 with cost: 1.697734553359878\n",
      "Epoch 1000 with cost: 1.6680420014082895\n",
      "Epoch 10000 with cost: 1.3910592693614807\n",
      "Epoch 100000 with cost: 0.6145896711798952\n",
      "Epoch 1000000 with cost: 0.31534522119154834\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([-0.012170782556997174, 0.7484944014006082, 1.5396491746592345], -0.053599965799610516)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#random initialization of weights and bias \n",
    "w = randn(3)\n",
    "b = randn(1)[1]\n",
    "\n",
    "w, b = train_batch_gradient_descent(train_x, train_y, w, b, 0.000001, 1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 with cost: 0.31534519677326356\n",
      "Epoch 10 with cost: 0.31534497700999503\n",
      "Epoch 100 with cost: 0.3153427795054063\n",
      "Epoch 1000 with cost: 0.3153208172610333\n",
      "Epoch 10000 with cost: 0.3151024667856411\n",
      "Epoch 100000 with cost: 0.3130386167929044\n",
      "Epoch 1000000 with cost: 0.2999624686893665\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([-0.01428750704562652, 1.262010425141379, 1.5668715436555116], -0.38665064635636504)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using w,b assigned above\n",
    "w, b = train_batch_gradient_descent(train_x, train_y, w, b, 0.000001, 1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 with cost: 0.2999624590332158\n",
      "Epoch 10 with cost: 0.29996237212818094\n",
      "Epoch 100 with cost: 0.2999615031096004\n",
      "Epoch 1000 with cost: 0.2999528160993786\n",
      "Epoch 10000 with cost: 0.2998662622744392\n",
      "Epoch 100000 with cost: 0.2990311122890295\n",
      "Epoch 1000000 with cost: 0.2927999589535113\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([-0.015162733620390877, 1.5438643384796278, 1.5651062397162048], -0.6987150074923895)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w, b = train_batch_gradient_descent(train_x, train_y, w, b, 0.000001, 1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predict (generic function with 1 method)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function predict(x, y, w, b)\n",
    "    if σ(w'x+b) >= .5\n",
    "        return 1\n",
    "    else\n",
    "        return 0\n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16\n"
     ]
    }
   ],
   "source": [
    "mean_error = 0.0\n",
    "for i = 1:length(train_x)\n",
    "    mean_error += (predict(train_x[i], train_y[i], w, b)-train_y[i])^2\n",
    "end\n",
    "println(mean_error/length(train_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15-element Array{Tuple{Array{Float64,1},Int64},1}:\n",
       " ([750.0, 3.9, 4.0], 1)\n",
       " ([730.0, 3.7, 6.0], 1)\n",
       " ([710.0, 3.7, 6.0], 1)\n",
       " ([770.0, 3.3, 3.0], 1)\n",
       " ([580.0, 2.7, 4.0], 0)\n",
       " ([590.0, 2.3, 3.0], 0)\n",
       " ([620.0, 3.3, 2.0], 1)\n",
       " ([600.0, 2.0, 1.0], 0)\n",
       " ([550.0, 2.3, 4.0], 0)\n",
       " ([550.0, 2.7, 1.0], 0)\n",
       " ([570.0, 3.0, 2.0], 0)\n",
       " ([660.0, 3.3, 5.0], 1)\n",
       " ([660.0, 4.0, 4.0], 1)\n",
       " ([680.0, 3.3, 5.0], 1)\n",
       " ([650.0, 2.3, 1.0], 0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test data\n",
    "test_x = [[x[1], x[2], x[3]] for x in zip(test.gmat, test.gpa, test.work_experience)]\n",
    "test_y = [x for x in test.admitted]\n",
    "test_data = [x for x in zip(test_x, test_y)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running algorithm on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "average_cost (generic function with 1 method)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "σ(x) = 1/(1+ exp(-x))\n",
    "\n",
    "function cross_entropy_loss(x, y, w, b)\n",
    "    return -y*log(σ(w'x + b)) - (1-y)*log(1- σ(w'x + b))\n",
    "end\n",
    "\n",
    "function average_cost(features, labels, w, b)\n",
    "    N = length(features)\n",
    "    return (1/N)*sum([cross_entropy_loss(features[i], labels[i], w, b) for i = 1:N])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "batch_gradient_descent (generic function with 1 method)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function batch_gradient_descent(features, labels, w, b, α)\n",
    "    del_w = [0.0 for i = 1:length(w)]\n",
    "    del_b = 0.0\n",
    "    \n",
    "    N = length(features)\n",
    "    \n",
    "    for i = 1:N\n",
    "        del_w += (σ(w'features[i]+b) - labels[i])*features[i]\n",
    "        del_b += (σ(w'features[i]+b) - labels[i])\n",
    "    end\n",
    "    \n",
    "    w = w - α*del_w\n",
    "    b = b - α*del_b\n",
    "    \n",
    "    return w, b\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The initial cost is: 0.6931471805599453\n",
      "The new cost is: 0.6897379588079332\n",
      "The new cost is: 0.68731872501649\n",
      "The new cost is: 0.6856011930418255\n"
     ]
    }
   ],
   "source": [
    "w = [0.0, 0.0, 0.0]\n",
    "b = 0.0\n",
    "println(\"The initial cost is: \", average_cost(test_x, test_y, w, b))\n",
    "\n",
    "w, b = batch_gradient_descent(test_x, test_y, w, b, 0.0000001)\n",
    "println(\"The new cost is: \", average_cost(test_x, test_y, w, b))\n",
    "\n",
    "w, b = batch_gradient_descent(test_x, test_y, w, b, 0.0000001)\n",
    "println(\"The new cost is: \", average_cost(test_x, test_y, w, b))\n",
    "\n",
    "w, b = batch_gradient_descent(test_x, test_y, w, b, 0.0000001)\n",
    "println(\"The new cost is: \", average_cost(test_x, test_y, w, b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "batch_gradient_descent (generic function with 1 method)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function batch_gradient_descent(features, labels, w, b, α)\n",
    "    del_w = [0.0 for i = 1:length(w)]\n",
    "    del_b = 0.0\n",
    "    \n",
    "    N = length(features)\n",
    "    \n",
    "    for i = 1:N\n",
    "        del_w += (σ(w'features[i]+b) - labels[i])*features[i]\n",
    "        del_b += (σ(w'features[i]+b) - labels[i])\n",
    "    end\n",
    "    \n",
    "    w = w - α*del_w\n",
    "    b = b - α*del_b\n",
    "    \n",
    "    return w, b\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "test_batch_gradient_descent (generic function with 1 method)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function test_batch_gradient_descent(features, labels, w, b, α, epochs)\n",
    "    for i = 1:epochs\n",
    "        \n",
    "        w, b = batch_gradient_descent(features, labels, w, b, α)\n",
    "        \n",
    "        if i == 1\n",
    "            println(\"Epoch \", i, \" with cost: \", average_cost(test_x, test_y, w, b))\n",
    "        end\n",
    "        \n",
    "        if i == 10\n",
    "            println(\"Epoch \", i, \" with cost: \", average_cost(test_x, test_y, w, b))\n",
    "        end\n",
    "        \n",
    "        if i == 100\n",
    "            println(\"Epoch \", i, \" with cost: \", average_cost(test_x, test_y, w, b))\n",
    "        end\n",
    "        \n",
    "        if i == 1000\n",
    "            println(\"Epoch \", i, \" with cost: \", average_cost(test_x, test_y, w, b))\n",
    "        end\n",
    "        \n",
    "        if i == 10000\n",
    "            println(\"Epoch \", i, \" with cost: \", average_cost(test_x, test_y, w, b))\n",
    "        end\n",
    "        \n",
    "        if i == 100000\n",
    "            println(\"Epoch \", i, \" with cost: \", average_cost(test_x, test_y, w, b))\n",
    "        end\n",
    "        \n",
    "        if i == 1000000\n",
    "            println(\"Epoch \", i, \" with cost: \", average_cost(test_x, test_y, w, b))\n",
    "        end\n",
    "        \n",
    "        if i == 10000000\n",
    "            println(\"Epoch \", i, \" with cost: \", average_cost(test_x, test_y, w, b))\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return w, b\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 with cost: 84.46479790802545\n",
      "Epoch 10 with cost: 65.78169715802545\n",
      "Epoch 100 with cost: 0.640615368893551\n",
      "Epoch 1000 with cost: 0.6400653877413574\n",
      "Epoch 10000 with cost: 0.6346395963083428\n",
      "Epoch 100000 with cost: 0.5877927093831397\n",
      "Epoch 1000000 with cost: 0.4749454842722376\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([-0.011655922027250062, 1.6308276456454425, 0.6520970352847868], 0.6252010518163176)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#random initialization of weights and bias \n",
    "w = randn(3)\n",
    "b = randn(1)[1]\n",
    "\n",
    "w, b = test_batch_gradient_descent(test_x, test_y, w, b, 0.000001, 1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 with cost: 0.474945443419782\n",
      "Epoch 10 with cost: 0.47494507574865186\n",
      "Epoch 100 with cost: 0.47494139913354877\n",
      "Epoch 1000 with cost: 0.4749046425953545\n",
      "Epoch 10000 with cost: 0.47453803167649206\n",
      "Epoch 100000 with cost: 0.47096147795253346\n",
      "Epoch 1000000 with cost: 0.44149744938233004\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([-0.012853418284992051, 2.1092273614214068, 0.5974533011824606], 0.10849657236775667)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using w,b assigned above\n",
    "w, b = test_batch_gradient_descent(test_x, test_y, w, b, 0.000001, 1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 with cost: 0.4414974214801037\n",
      "Epoch 10 with cost: 0.4414971703604529\n",
      "Epoch 100 with cost: 0.44149465920209496\n",
      "Epoch 1000 with cost: 0.4414695514326542\n",
      "Epoch 10000 with cost: 0.4412188543007811\n",
      "Epoch 100000 with cost: 0.4387491059840249\n",
      "Epoch 1000000 with cost: 0.41709081998654524\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([-0.013602825259597221, 2.453200636145337, 0.5745545892345967], -0.3877274323863138)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w, b = test_batch_gradient_descent(test_x, test_y, w, b, 0.000001, 1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predict (generic function with 1 method)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function predict(x, y, w, b)\n",
    "    if σ(w'x+b) >= .5\n",
    "        return 1\n",
    "    else\n",
    "        return 0\n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26666666666666666\n"
     ]
    }
   ],
   "source": [
    "mean_error = 0.0\n",
    "for i = 1:length(test_x)\n",
    "    mean_error += (predict(test_x[i], test_y[i], w, b)-test_y[i])^2\n",
    "end\n",
    "println(mean_error/length(test_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can conclude that there is high accuracy in predicting whether or not a student got an admission. However, the train data appears to be more accurate with an average mean error of 0.16 vs 0.27 for the test data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.3",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
